{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "data = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imdb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-21baf7c0756e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imdb' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> please give this one a miss br br <UNK <UNK and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK so all you madison fans give this a miss\n"
     ]
    }
   ],
   "source": [
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "print(decode_review(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value = word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value = word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "print(len(test_data), len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.6920 - accuracy: 0.5381 - val_loss: 0.6899 - val_accuracy: 0.6317\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6860 - accuracy: 0.7053 - val_loss: 0.6819 - val_accuracy: 0.7353\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.7494 - val_loss: 0.6663 - val_accuracy: 0.7466\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6515 - accuracy: 0.7637 - val_loss: 0.6411 - val_accuracy: 0.7615\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6190 - accuracy: 0.7877 - val_loss: 0.6072 - val_accuracy: 0.7850\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.8095 - val_loss: 0.5674 - val_accuracy: 0.8024\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 0.8281 - val_loss: 0.5259 - val_accuracy: 0.8201\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.8447 - val_loss: 0.4856 - val_accuracy: 0.8303\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4447 - accuracy: 0.8585 - val_loss: 0.4500 - val_accuracy: 0.8407\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4066 - accuracy: 0.8691 - val_loss: 0.4193 - val_accuracy: 0.8490\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3739 - accuracy: 0.8801 - val_loss: 0.3941 - val_accuracy: 0.8559\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.8876 - val_loss: 0.3737 - val_accuracy: 0.8614\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8933 - val_loss: 0.3573 - val_accuracy: 0.8642\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8985 - val_loss: 0.3442 - val_accuracy: 0.8681\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2845 - accuracy: 0.9043 - val_loss: 0.3318 - val_accuracy: 0.8738\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2683 - accuracy: 0.9084 - val_loss: 0.3226 - val_accuracy: 0.8774\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2541 - accuracy: 0.9131 - val_loss: 0.3169 - val_accuracy: 0.8755\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2429 - accuracy: 0.9157 - val_loss: 0.3085 - val_accuracy: 0.8791\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2301 - accuracy: 0.9212 - val_loss: 0.3035 - val_accuracy: 0.8800\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2195 - accuracy: 0.9254 - val_loss: 0.2988 - val_accuracy: 0.8810\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9291 - val_loss: 0.2956 - val_accuracy: 0.8821\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2004 - accuracy: 0.9329 - val_loss: 0.2926 - val_accuracy: 0.8837\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1922 - accuracy: 0.9368 - val_loss: 0.2905 - val_accuracy: 0.8837\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1839 - accuracy: 0.9401 - val_loss: 0.2887 - val_accuracy: 0.8844\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1763 - accuracy: 0.9433 - val_loss: 0.2873 - val_accuracy: 0.8846\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1694 - accuracy: 0.9455 - val_loss: 0.2865 - val_accuracy: 0.8840\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1625 - accuracy: 0.9481 - val_loss: 0.2863 - val_accuracy: 0.8848\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9515 - val_loss: 0.2860 - val_accuracy: 0.8856\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1500 - accuracy: 0.9541 - val_loss: 0.2859 - val_accuracy: 0.8871\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1444 - accuracy: 0.9563 - val_loss: 0.2864 - val_accuracy: 0.8866\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1388 - accuracy: 0.9595 - val_loss: 0.2880 - val_accuracy: 0.8856\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1344 - accuracy: 0.9597 - val_loss: 0.2882 - val_accuracy: 0.8868\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.9626 - val_loss: 0.2895 - val_accuracy: 0.8864\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1243 - accuracy: 0.9642 - val_loss: 0.2916 - val_accuracy: 0.8868\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9664 - val_loss: 0.2936 - val_accuracy: 0.8866\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1148 - accuracy: 0.9677 - val_loss: 0.2969 - val_accuracy: 0.8830\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1111 - accuracy: 0.9687 - val_loss: 0.2978 - val_accuracy: 0.8854\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9706 - val_loss: 0.3000 - val_accuracy: 0.8853\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9723 - val_loss: 0.3023 - val_accuracy: 0.8832\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0993 - accuracy: 0.9737 - val_loss: 0.3057 - val_accuracy: 0.8833\n",
      "782/782 [==============================] - 1s 910us/step - loss: 0.3280 - accuracy: 0.8714\n",
      "[0.3279705047607422, 0.8714399933815002]\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fitmodel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  \n",
      "<START> please give this one a miss br br <UNK <UNK and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Prediction:  [1.7148149e-18]\n",
      "Actual:  0\n",
      "[0.3279705047607422, 0.8714399933815002]\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[0]\n",
    "predict = model.predict([test_review])\n",
    "print(\"Review:  \")\n",
    "print(decode_review(test_review))\n",
    "print(\"Prediction:  \" + str(predict[0]))\n",
    "print(\"Actual:  \" + str(test_labels[0]))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
